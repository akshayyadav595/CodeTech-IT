
# pip install textblob transformers pandas matplotlib

import pandas as pd
from textblob import TextBlob
import matplotlib.pyplot as plt
from transformers import pipeline
data = {
    "text": [
        "I love this product! It's amazing.",
        "This is the worst service I've ever experienced.",
        "The food was decent, nothing extraordinary.",
        "Absolutely fantastic! Will buy again.",
        "I'm not happy with this purchase, it was a waste of money."
    ]
}

df = pd.DataFrame(data)

def get_sentiment(text):
    blob = TextBlob(text)
    polarity = blob.sentiment.polarity
    subjectivity = blob.sentiment.subjectivity
    return polarity, subjectivity

df['polarity'], df['subjectivity'] = zip(*df['text'].apply(get_sentiment))

df['sentiment'] = df['polarity'].apply(lambda x: 'Positive' if x > 0 else ('Negative' if x < 0 else 'Neutral'))

plt.figure(figsize=(8,6))
df['sentiment'].value_counts().plot(kind='bar', color=['green', 'gray', 'red'])
plt.title('Sentiment Distribution (TextBlob)')
plt.xlabel('Sentiment')
plt.ylabel('Count')
plt.xticks(rotation=0)
plt.show()
sentiment_pipeline = pipeline("sentiment-analysis")

texts = [
    "I love this product! It's amazing.",
    "This is the worst service I've ever experienced.",
    "The food was decent, nothing extraordinary.",
    "Absolutely fantastic! Will buy again.",
    "I'm not happy with this purchase, it was a waste of money."
]

results = sentiment_pipeline(texts)
for text, result in zip(texts, results):
    print(f"Text: {text}")
    print(f"Sentiment: {result['label']}, Confidence Score: {result['score']:.2f}")
    print("-" * 80)

bert_labels = [result['label'] for result in results]
plt.figure(figsize=(8,6))
pd.Series(bert_labels).value_counts().plot(kind='bar', color=['green', 'red'])
plt.title('Sentiment Distribution (BERT)')
plt.xlabel('Sentiment')
plt.ylabel('Count')
plt.xticks(rotation=0)
plt.show()
import numpy as np
import pandas as pd
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report


iris = load_iris()
X = iris.data  
y = iris.target 


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)


model = RandomForestClassifier(n_estimators=100, random_state=42)


model.fit(X_train, y_train)


y_pred = model.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)
print("\nClassification Report:\n", classification_report(y_test, y_pred))


sample_data = [[5.1, 3.5, 1.4, 0.2]]  
predicted_class = model.predict(sample_data)
print("\nPredicted class:", iris.target_names[predicted_class[0]])

import dash
from dash import dcc, html
import plotly.express as px
import pandas as pd
df = pd.read_csv("transactions.csv")
customer_transactions = df.groupby("customer_id")["transaction_id"].count().reset_index()
customer_transactions.columns = ["Customer ID", "Total Transactions"]

customer_spending = df.groupby("customer_id")["amount"].sum().reset_index()
customer_spending.columns = ["Customer ID", "Total Spending"]

category_avg = df.groupby("category")["amount"].mean().reset_index()
category_avg.columns = ["Category", "Average Amount"]

app = dash.Dash(_name_)

fig_transactions = px.bar(customer_transactions, x="Customer ID", y="Total Transactions",
                          title="Total Transactions per Customer", color="Total Transactions")

fig_spending = px.bar(customer_spending, x="Customer ID", y="Total Spending",
                      title="Total Spending per Customer", color="Total Spending")

fig_category_avg = px.bar(category_avg, x="Category", y="Average Amount",
                          title="Average Spending per Category", color="Average Amount")

app.layout = html.Div(children=[
    html.H1("Customer Transaction Dashboard", style={'text-align': 'center'}),
    
    html.Div(children=[
        html.H3("Total Transactions per Customer"),
        dcc.Graph(figure=fig_transactions),
    ]),
    
    html.Div(children=[
        html.H3("Total Spending per Customer"),
        dcc.Graph(figure=fig_spending),
    ]),

    html.Div(children=[
        html.H3("Average Transaction Amount per Category"),
        dcc.Graph(figure=fig_category_avg),
    ])
])

if _name_ == '_main_':
    app.run_server(debug=True)

from pyspark.sql import SparkSession
from pyspark.sql.functions import col, sum, avg, count, desc
spark = SparkSession.builder \
    .appName("Customer Transaction Analysis") \
    .getOrCreate()
df = spark.read.csv("transactions.csv", header=True, inferSchema=True)
df.printSchema()  
df.show(5)       
customer_transactions = df.groupBy("customer_id") \
    .agg(count("transaction_id").alias("total_transactions")) \
    .orderBy(desc("total_transactions"))
customer_spending = df.groupBy("customer_id") \
    .agg(sum("amount").alias("total_spent")) \
    .orderBy(desc("total_spent"))
category_avg = df.groupBy("category") \
    .agg(avg("amount").alias("avg_amount")) \
    .orderBy(desc("avg_amount"))
customer_transactions.show(10)
customer_spending.show(10)
category_avg.show(10)
customer_spending.write.csv("customer_spending_output.csv",Â header=True)
